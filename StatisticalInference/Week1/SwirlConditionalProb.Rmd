
Practice Programming Assignment: swirl Lesson : Conditional Probability.
=========================

 (Slides for this and other Data Science courses may be found at github
 https://github.com/DataScienceSpecialization/courses/. If you care to use them, they must be downloaded
 as a zip file and viewed locally. This lesson corresponds to
 06_Statistical_Inference/03_Conditional_Probability.)

If you were given a fair die and asked what the probability of rolling a 3 is, what would you reply?

Given that there are 3 odd numbers on the die your possibilities have been reduced to 3 and you want to
 know the probability of 1 of them.

The probability of this second event is conditional on this new information, so the probability of
 rolling a 3 is now one third.

1: 1/3
2: 1/4
3: 1
4: 1/6
5: 1/2

Selection: 3


We represent the conditional probability of an event A given that B has occurred with the notation
 P(A|B). More specifically, we define the conditional probability of event A, given that B has occurred
 with the following.

P(A|B) = P(A & B)/ P(B) . P(A|B) is the probability that BOTH A and B occur divided by the probability
that B occurs.

Back to our dice example. Which of the following expressions represents P(A&B), where A is the event of
rolling a 3 and B is the event of the roll being odd?

Here A is a subset of B so the probability of both A AND B happening is the probability of A happening.

1: 1
2: 1/4
3: 1/2
4: 1/3
5: 1/6

Selection: 5

Continuing with the same dice example. Which of the following expressions represents P(A&B)/P(B), where A
is the event of rolling a 3 and B is the event of the roll being odd?

Here A is a subset of B so the probability of both A AND B happening is the probability of A happening.
The probability of B is the reciprocal of the number of odd numbers between 1 and 6 (inclusive).

1: (1/3)/(1/2)
2: 1/6
3: (1/6)/(1/2)
4: (1/2)/(1/6)

Selection: 3

From the definition of P(A|B), we can write P(A&B) = P(A|B) * P(B), right?  Let's use this to express
P(B|A).

P(B|A) = P(B&A)/P(A) = P(A|B) * P(B)/P(A). This is a simple form of Bayes' Rule which relates the two
conditional probabilities.

Suppose we don't know P(A) itself, but only know its conditional probabilities, that is, the probability
that it occurs if B occurs and the probability that it occurs if B doesn't occur. These are P(A|B) and
P(A|~B), respectively. We use ~B to represent 'not B' or 'B complement'.

We can then express 

P(A) = P(A|B) * P(B) + P(A|~B) * P(~B) 

and substitute this is into the denominator of Bayes' Formula.

P(B|A) = P(A|B) * P(B) / ( P(A|B) * P(B) + P(A|~B) * P(~B) )

 Let 'D' be the event that the patient has HIV, and let '+' indicate a positive test result and '-' a
negative. What information do we know? Recall that we know the accuracy rates of the HIV test.

1: P(+|~D) and P(-|D)
2: P(+|~D) and P(-|~D)
3: P(+|D) and P(-|D)
4: P(+|D) and P(-|~D)

Selection: 4

Suppose a person gets a positive test result and comes from a population with a HIV prevalence rate of
 .001. We'd like to know the probability that he really has HIV. Which of the following represents this?

1: P(D|+)
2: P(+|D)
3: P(~D|+)
4: P(D|-)

Selection: 1

By Bayes' Formula, P(D|+) = P(+|D) * P(D) / ( P(+|D) * P(D) + P(+|~D) * P(~D) )

We can use the prevalence of HIV in the patient's population as the value for P(D). Note that since
P(~D)=1-P(D) and P(+|~D) = 1-P(-|~D) we can calculate P(D|+). In other words, we know values for all the
terms on the right side of the equation. Let's do it!
```r
> (0.997*0.001)
[1] 0.000997
```
Now solve for the remainder of the denominator, P(+|~D)*P(~D).
```r
> ((1-0.985)*(1-0.001))
[1] 0.014985
```

Now put the pieces together to compute the probability that the patient has the disease given his
positive test result, P(D|+). Plug your last two answers into the formula 
P(+|D) * P(D) / ( P(+|D) * P(D) + P(+|~D) * P(~D) ) to compute P(D|+).

```r
> (.997*.001) / (.997*.001 + .015*.999)
[1] 0.06238268
```

So the patient has a 6% chance of having HIV given this positive test result. The expression P(D|+) is
called the positive predictive value. Similarly, P(~D|-), is called the negative predictive value, the
probability that a patient does not have the disease given a negative test result.


The diagnostic likelihood ratio of a positive test, DLR_+, is the ratio of the two + conditional
probabilities, one given the presence of disease and the other given the absence. Specifically, DLR_+ =
P(+|D) / P(+|~D). Similarly, the DLR_- is defined as a ratio. Which of the following do you think
represents the DLR_-?

1: P(-|D) / P(-|~D)
2: P(-|D) / P(+|~D)
3: I haven't a clue.
4: P(+|~D) / P(-|D)

Selection: 1

Recall that P(+|D) and P(-|~D), (test sensitivity and specificity respectively) are accuracy rates of a
diagnostic test for the two possible results. They should be close to 1 because no one would take an
inaccurate test, right? Since DLR_+ = P(+|D) / P(+|~D) we recognize the numerator as test sensitivity and the denominator as the complement of test specificity.

Since the numerator is close to 1 and the denominator is close to 0 do you expect DLR_+ to be large or
small?

1: Small
2: Large
3: I haven't a clue.

Selection: 2

Now recall that DLR_- = P(-|D) / P(-|~D). Here the numerator is the complement of sensitivity and the
denominator is specificity. From the arithmetic and what you know about accuracy tests, do you expect
DLR_- to be large or small?

1: I haven't a clue.
2: Small
3: Large

Selection: 2

Now a little more about likelihood ratios. Recall Bayes Formula. 
P(D|+) = P(+|D) * P(D) / ( P(+|D) * P(D)  + P(+|~D) * P(~D) ) 
and notice that if we replace all occurrences of 'D' with '~D', the denominator
doesn't change. This means that if we formed a ratio of P(D|+) to P(~D|+) we'd get a much simpler
expression (since the complicated denominators would cancel each other out). Like this....

P(D|+) / P(~D|+) = P(+|D) * P(D) / (P(+|~D) * P(~D)) = P(+|D)/P(+|~D) * P(D)/P(~D)

The left side of the equation represents the post-test odds of disease given a positive test result. The
equation says that the post-test odds of disease equals the pre-test odds of disease (that is, P(D)/P(~D)
) times

1: I haven't a clue.
2: the DLR_-
3: the DLR_+

Selection: 3

 In other words, a DLR_+ value equal to N indicates that the hypothesis of disease is N times more supported by the data than the hypothesis of no disease.


